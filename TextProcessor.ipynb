{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextProcessor\n",
    "\n",
    "### Set environmental variables\n",
    "\n",
    "In order to properly load modules within this notebook from outside the repository folder, set the script **PATH** below,  e.g. ```C:/TextProcessor```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/path/to/TextProcessor\" # <-- optional if running from native path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib.util, os\n",
    "\n",
    "if not os.path.isdir(PATH):\n",
    "    PATH = os.getcwd()\n",
    "PATH = os.path.realpath(PATH)\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"__init__\", PATH+'/__init__.py')\n",
    "init = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(init)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from kwic import run_kwic\n",
    "from nltklib import nlp_text, ngram_an, pos_tagger\n",
    "from textractlib import textract_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read document file\n",
    "\n",
    "Supported formats include `.doc(x)`, `.epub`, `.odt` and `.pdf`. **To-do:** add whole folder conversion with recursion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"\" # <-- file containing text to parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = textract_file(input_path, convert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(text.replace('\\n\\n','\\n').split('\\n')) # <-- text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KWIC Analysis\n",
    "\n",
    "Look for keywords in context in a text file or string, return associated tags. **Hint:** try changing associated `size` (5) for different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"\" # <-- keyword to analyze context\n",
    "\n",
    "run_kwic(text, keyword, size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing\n",
    "\n",
    "#### N-gram analysis\n",
    "\n",
    "Requires the Natural Language Toolkit installed. **Hint:** try changing the default `n-value` (2) for different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grams = ngram_an(text, n=2)\n",
    "for g in grams:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Syntax analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform analysis using `spaCy`, a library for Natural Language Processing featuring NER, POS tagging, dependency parsing, word vectors and more.\n",
    "\n",
    "**Note:** it is required to download the NLP model if you're running for the first time e.g. by executing ```python -m spacy download en``` for english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp_text(text, 'en') # 'en_core_web_sm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS tagging\n",
    "\n",
    "Returns part-of-speech tagging from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pos_tagger(doc); tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze syntax\n",
    "\n",
    "Gets nouns, verbs and entities from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Noun phrases:\\n\", np.array([chunk.text for chunk in doc.noun_chunks]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Verbs:\\n\", np.array([token.lemma_ for token in doc if token.pos_ == \"VERB\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Entities:\")\n",
    "for entity in doc.ents:\n",
    "    print(entity.label_, '=>', entity.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compress output â†’  `output.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip output.zip *csv *txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Download output files](output.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "### References\n",
    "\n",
    "* Natural Language Toolkit: https://www.nltk.org/\n",
    "\n",
    "* spaCy documentation: https://spacy.io\n",
    "\n",
    "* textract documentation: http://textract.readthedocs.io/en/latest/\n",
    "\n",
    "* textract @ GitHub: https://github.com/deanmalmgren/textract\n",
    "\n",
    "* tika-python @ GitHub: https://github.com/chrismattmann/tika-python\n",
    "\n",
    "* KWIC implementation by @vahbuna: https://github.com/vahbuna/kwic/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
