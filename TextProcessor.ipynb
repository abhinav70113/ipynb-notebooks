{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextProcessor\n",
    "\n",
    "### Set environmental variables\n",
    "\n",
    "In order to properly load modules within this notebook from outside the repository folder, set the script **PATH** below,  e.g. ```C:/TextProcessor```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/path/to/TextProcessor\" # <-- optional if running from native path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util, os\n",
    "\n",
    "if not os.path.isdir(PATH):\n",
    "    PATH = os.getcwd()\n",
    "PATH = os.path.realpath(PATH)\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"__init__\", PATH+'/__init__.py')\n",
    "init = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(init)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TextProcessor import TextProcessor\n",
    "from csvlib import read_from_csv\n",
    "from kwic import run_kwic\n",
    "from nltklib import ngram_an\n",
    "from spacylib import nlp_an\n",
    "from textractlib import textract_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process text from document\n",
    "\n",
    "Analyzes keywords in context, n-grams, part-of-speech tags, noun phrases, verbs and entities, writing all output to CSV files.\n",
    "\n",
    "**Hint:** the `keywords` parameter accepts either a single word, a list, a string list (comma separated) or an integer (for highest occurrences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = \"\" # text string or document file with content to parse\n",
    "keywords = \"\"   # keywords for KWIC and n-gram analyses e.g. \"love,hate\"\n",
    "column = \"\"     # column index or title to consider from spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced settings\n",
    "\n",
    "Set keywords in context and n-grams size, among other settings. **Hint:** try changing `kwic_size` and `ngram_size` for different results.\n",
    "\n",
    "**Note:** required [NLP models](https://spacy.io/usage/models) can be installed by enabling `allow_download` or by executing e.g. `python -m spacy download en` for English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwic_size = 5           # size of keywords in context\n",
    "ngram_size = 2          # size of n-grams to analyze\n",
    "append_columns = \"\"     # for KWIC and n-grams e.g. \"text\"\n",
    "\n",
    "nlp = True              # enable natural language processing (spaCy)\n",
    "ignore_case = True      # do not consider case letters (AaBbCc)\n",
    "allow_download = False  # automatic model download from spaCy\n",
    "convert = False         # extract text from document and exit\n",
    "\n",
    "model = \"auto\"          # model selection from spaCy (e.g. \"english\")\n",
    "encode = \"utf-8\"        # file encoding (e.g. \"windows-1252\")\n",
    "binary = \"\"             # binary name to extract text from file\n",
    "\n",
    "output_folder = \"TEXT\"  # output folder name to write results to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start analysis\n",
    "\n",
    "Launch KWIC, n-gram and syntax analyses, and write results to the `output_folder` set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwic, grams, pos, nouns, verbs, entities = TextProcessor(text_input,\n",
    "                                                         output_folder=output_folder,\n",
    "                                                         keywords=keywords,\n",
    "                                                         column=column, \n",
    "                                                         kwic_size=kwic_size,\n",
    "                                                         ngram_size=ngram_size,\n",
    "                                                         nlp=nlp, \n",
    "                                                         ignore_case=ignore_case,\n",
    "                                                         append_columns=append_columns,\n",
    "                                                         allow_download=allow_download,\n",
    "                                                         model=model,\n",
    "                                                         encode=encode,\n",
    "                                                         convert=convert,\n",
    "                                                         binary=binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keywords in context\n",
    "\n",
    "Returns data frame built from keywords in context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-gram analysis\n",
    "\n",
    "Returns data frame built from Natural Language Toolkit (NLTK)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parts-of-speech tags\n",
    "\n",
    "Returns data frame of POS tags from spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noun chunks\n",
    "\n",
    "Returns data frame of noun phrases from spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbs\n",
    "\n",
    "Returns data frame of verbs after lemmatization performed by spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entities\n",
    "\n",
    "Returns identified entities from spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compress output â†’  `output.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r output.zip TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Download output files](output.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "### References\n",
    "\n",
    "* Natural Language Toolkit: https://www.nltk.org/\n",
    "\n",
    "* spaCy documentation: https://spacy.io\n",
    "\n",
    "* textract documentation: http://textract.readthedocs.io/en/latest/\n",
    "\n",
    "* textract @ GitHub: https://github.com/deanmalmgren/textract\n",
    "\n",
    "* tika-python @ GitHub: https://github.com/chrismattmann/tika-python\n",
    "\n",
    "* Original KWIC code: https://github.com/vahbuna/kwic/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
