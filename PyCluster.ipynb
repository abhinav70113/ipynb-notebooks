{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyCluster\n",
    "\n",
    "### Set environmental variables\n",
    "\n",
    "In order to properly load modules within this notebook from outside the repository folder, set the script **PATH** below,  e.g. ```C:/PyCluster```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH = \"/path/to/PyCluster\" # <-- optional if running from native path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib.util, os\n",
    "\n",
    "if not os.path.isdir(PATH):\n",
    "    PATH = os.getcwd()\n",
    "PATH = os.path.realpath(PATH)\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"__init__\", PATH+'/__init__.py')\n",
    "init = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(init)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.offline as py\n",
    "\n",
    "from chart import line_chart\n",
    "from media import cluster_media\n",
    "from tweets import cluster_tweets\n",
    "\n",
    "py.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze data\n",
    "\n",
    "Calculate the appropriate **k** number of clusters for k-means and start data analysis. Alternatively, leave it as `0` for elbow method (auto-detection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_name = \"\" # data set to parse\n",
    "k_value    = 0  # set number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced settings\n",
    "\n",
    "Allows setting interval to split data, number of clusters, performing k-value accuracy tests. **Note:** the `classic_k_means` method has been deprecated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_features = 0             # number of tweets X axis\n",
    "n_dimensions = 0           # number of words Y axis\n",
    "num_days = 0               # interval to split data\n",
    "\n",
    "tfidf = True               # perform tf-idf processing\n",
    "mini_batch = True          # faster at expense of accuracy\n",
    "\n",
    "elbow_method = False       # within-cluster sum of square\n",
    "silhouette_scores = False  # silhouette coefficients\n",
    "gap_statistics = False     # calculate gap statistics\n",
    "all_metrics = False        # virality/ASS/topic complexity\n",
    "\n",
    "random_state = None        # optionally set random seed\n",
    "\n",
    "np.random.seed(random_state) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read tweets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df, ag, tg, mm, mx = cluster_tweets(input_name,\n",
    "                                    k=k_value,\n",
    "                                    days=num_days,\n",
    "                                    tfidf=tfidf,\n",
    "                                    minibatch=mini_batch,\n",
    "                                    elb=elbow_method,\n",
    "                                    sil=silhouette_scores,\n",
    "                                    gap=gap_statistics,\n",
    "                                    random_state=random_state,\n",
    "                                    all_metrics=all_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read news media data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df, ag, tg, mm, mx = cluster_media(input_name,\n",
    "                                   k=k_value,\n",
    "                                   days=num_days,\n",
    "                                   tfidf=tfidf,\n",
    "                                   minibatch=mini_batch,\n",
    "                                   elb=elbow_method,\n",
    "                                   sil=silhouette_scores,\n",
    "                                   gap=gap_statistics,\n",
    "                                   random_state=random_state,\n",
    "                                   all_metrics=all_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention graph\n",
    "\n",
    "Plot overall narrative attention over time, i.e. the amount of input data during the period analyzed. **Tip:** smaller time frames result in more detailed steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "line_chart(ag, inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Themed graph\n",
    "\n",
    "Plot clusters and their attention over time. **Note:** groups are named after their most occurring word, but defined by word co-occurrences (k-means)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "line_chart(tg, inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details on clusters\n",
    "\n",
    "Returns data frame with detailed data on a specific cluster `k`. By default, shows objects from the first cluster (`k=0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "\n",
    "df[df['cluster'] == k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov chain\n",
    "\n",
    "Displays markov matrix describing a sequence of possible events in which the probability of each event depends on the previous state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from markov import markov_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Render transition diagram\n",
    "\n",
    "Methods available for rendering the transition diagram: `graphviz` or `pygraphviz` or `pydot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Q = list(mm.values())\n",
    "states = list(mm.keys())\n",
    "m = markov_chain(Q, states, method='graphviz'); m\n",
    "#Image(m) # <-- uncomment for pygraphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cause-effect structure `WIP`\n",
    "\n",
    "Integrated information theory provides a mathematical framework to fully characterize the cause-effect structure of a physical system. Here we use [PyPhi](http://integratedinformationtheory.org), which implements a framework for causal analysis and unfolds the full cause-effect structure of discrete dynamical systems of binary elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phi import run_pyphi, complex_mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute network\n",
    "\n",
    "Returns all complexes in the network context of all φ and Φ computation. Here we’ll use the 2-dimensional state-by-node form for the TPM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bc, ac = run_pyphi(mx['presence_matrix'],\n",
    "                   #cm=mx['connective_matrix'], # <-- optional\n",
    "                   states=mx['states'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mechanism details\n",
    "\n",
    "See details (cause and effect) of one selected mechanism, based on the list above and small phi values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = 0 # <-- mechanism number\n",
    "\n",
    "complex_mechanism(bc, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best complex data\n",
    "\n",
    "Display first mechanism after system irreducibility analysis and its cause-effect structure of the complex with the highest phi value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALL complexes data (!)\n",
    "\n",
    "Display all complexes identified by PyPhi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compress output →  `output.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip output.zip *html *json *csv *xls *xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Download output files](output.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "### References:\n",
    "\n",
    "* Scipy: [documentation](https://www.scipy.org/) | [GitHub](https://github.com/scipy/scipy)\n",
    "\n",
    "* Scikit-learn: [documentation](https://scikit-learn.org/stable/documentation.html) | [GitHub](https://github.com/scipy/scipy)\n",
    "\n",
    "* PyPhi: [website](https://pypi.org/project/pyphi/) | [arxiv](https://arxiv.org/abs/1712.09644) | [documentation](https://pyphi.readthedocs.io/en/latest/) | [GitHub](https://github.com/wmayner/pyphi)\n",
    "\n",
    "* Mini-Batch K-means : [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html#sklearn.cluster.MiniBatchKMeans) | [article](https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf)\n",
    "\n",
    "* Gap Statistic for k-means: [anaconda](https://anaconda.org/milesgranger/gap-statistic/notebook)\n",
    "\n",
    "* PyGraphviz documentation: [GitHub](https://pygraphviz.github.io/)\n",
    "\n",
    "* PyDot markov chains: [Vince Knight](https://vknight.org/unpeudemath/code/2015/11/15/Visualising-markov-chains.html)\n",
    "\n",
    "* Original d3-cloud by Jason Davies: [GitHub](http://github.com/jasondavies/d3-cloud)\n",
    "\n",
    "* Based on twarc's implementation: [GitHub](https://github.com/DocNow/twarc)\n",
    "\n",
    "* Wordle algorithm due to: [Jonathan Feinberg](http://static.mrfeinberg.com/bv_ch03.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
